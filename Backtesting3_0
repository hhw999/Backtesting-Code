# 4 Hour directional Bias Def Stats
import pandas as pd
import yfinance as yf
import mplfinance as mpf
import bokeh
import matplotlib.pyplot as plt
from matplotlib.widgets import Cursor
import matplotlib.dates as mdates
from bokeh.plotting import figure, output_file
from bokeh.io import output_notebook, show
from bokeh.resources import INLINE
from backtesting import Backtest, Strategy
from backtesting.lib import crossover, plot_heatmaps, resample_apply, barssince
from datetime import datetime, time, timedelta
from pytz import UTC  # Import the UTC timezone from pytz library
from tqdm import tqdm

def identify_bar(data):
    """Add a 'bar' column with 'Red' or 'Green' based on Close and Open prices."""
    data = data.copy()
    data['Bar'] = 'Green'  # Initialize 'bar' column with 'Green'
    red_mask = data['Close'] < data['Open']  # Create a mask for 'Red' bars
    data.loc[red_mask, 'Bar'] = 'Red'  # Set 'bar' to 'Red' for rows where Close < Open
    return data

def identify_fractals(data):
    """Identify fractals based off of code from Trading view"""
    
    # Fractal period
    fractal_period = 5
    fractal_dates = []

    def is_bill_williams_fractal(high, low, index):
        if index < 4 or index >= len(high) - 4:
            return False
        fractal_high = high[index]
        fractal_low = low[index]
        is_high = fractal_high >= max(high[index - 2:index + 3])
        is_low = fractal_low <= min(low[index - 2:index + 3]) 
        # is_high = fractal_high >= max(high[index - 2:index + 2]) and fractal_high >= max(high[index - 1:index + 4])
        # is_low = fractal_low <= min(low[index - 2:index + 2]) and fractal_low <= min(low[index - 1:index + 4])
        
        if is_high == True: return +1
        elif is_low == True: return -1

    # Return high or low fractal
    for i in range(len(data)):
        if is_bill_williams_fractal(data['High'], data['Low'], i) == +1:
            fractal_dates.append((data.index[i], 'fractal_high'))
        
        elif is_bill_williams_fractal(data['High'], data['Low'], i) == -1:
            fractal_dates.append((data.index[i], 'fractal_low'))

    data['Fractal'] = ''
    for date, fractal_type in fractal_dates:
        data.loc[date, 'Fractal'] = fractal_type

    data = data.dropna(subset=['Open'])
    data.index = data.index.tz_localize(None)

    return data

def determine_directional_bias(data):
    global H4_high, H4_low, directional_bias, H4_high_from_fractal, H4_low_from_fractal, h4_data_fractal  # Declare these variables as global

    if H4_high > 0 and H4_low > 0:
        previous_h4_high = H4_high
        previous_h4_low = H4_low

        # Helper function to fetch the next available bar with data using relative indexing
        def get_next_bar_with_data(current_pos):
            next_pos = current_pos + 1  # Start with the very next position
            while next_pos < len(h4_data_fractal) and h4_data_fractal.iloc[next_pos].isna().all():  # Keep iterating if the row has all NaN values
                next_pos += 1
            if next_pos < len(h4_data_fractal):  # If we're still within the DataFrame bounds
                return h4_data_fractal.iloc[next_pos]
            else:
                print(f"No data available after position: {current_pos}")
                return None

        current_pos = h4_data_fractal.index.get_loc(data.name)
        
        next_h4_bar = get_next_bar_with_data(current_pos)  # Get the next available bar with data
        if next_h4_bar is not None:
            # If the next_h4_bar was found, try to find the bar after that
            next_pos_for_bar2 = h4_data_fractal.index.get_loc(next_h4_bar.name)
            next_h4_bar2 = get_next_bar_with_data(next_pos_for_bar2)  
        else:
            next_h4_bar2 = None

        if data['High'] >= previous_h4_high and H4_high_from_fractal: 
            ### Interaction with upper H4 Level
            
            if data['Close'] > previous_h4_high and next_h4_bar['High'] > previous_h4_high and next_h4_bar['Close'] > data['High']:#3.11 CHANGE sft, next_h4_bar fully above level
                #Body close with bar2 body close above 
                directional_bias = 2  # Set bias as SFT to the up side)
            
            elif data['Close'] <= previous_h4_high: #3.9 CHANGE <= to <
                # Wick Close
                directional_bias = -1 # Set directional bias NFT to the up side
                if next_h4_bar['Close'] >= previous_h4_high or next_h4_bar2['Close'] >= previous_h4_high:
                    # bar2/bar3 body close
                    directional_bias = 1 # Set directional bias FT to the up side
            
            elif data['Close'] > previous_h4_high and next_h4_bar['Close'] <= previous_h4_high:
                # body close with bar2 closing below level
                directional_bias = -1 # Set directional bias NFT to the up side
                if next_h4_bar2['Close'] > previous_h4_high:
                    # bar3 closing above level after 1x body close
                    directional_bias = 1 # Set directional bias FT to the up side
            
            elif data['Close'] > previous_h4_high and next_h4_bar['Close'] > previous_h4_high:
                # body close with bar 2 closing above level
                directional_bias = 1 # set bias as FT to the up side

            else: print('error in setting directional bias up')
        
        elif data['Low'] <= previous_h4_low and H4_low_from_fractal: 
            ### Interaction with lower H4 Level

            if data['Close'] < previous_h4_low and next_h4_bar['Low'] < previous_h4_low and next_h4_bar['Close'] < data['Low']: #3.11 CHANGE sft, next_h4_bar fully below level
                # Body close with bar 2 body close below level
                directional_bias = -2 # Set bias a SFT to the down side
            
            elif data['Close'] >= previous_h4_low:
                # Wick close
                directional_bias = 1 # Set bias as NFT to the down side
                if next_h4_bar['Close'] <= previous_h4_low or next_h4_bar2['Close'] <= previous_h4_low:
                    # bar2/bar3 body close
                    directional_bias = -1 # Set bias as FT to the down side 

            elif data['Close'] < previous_h4_low and next_h4_bar['Close'] >= previous_h4_low:
                # body close with bar 2 closing above level
                directional_bias = 1 # Set bias as NFT to the down side
                if next_h4_bar2['Close'] < previous_h4_low:
                    #bar3 closing below level after 1x body close
                    directional_bias = -1 # Set bias as FT to the down side

            elif data['Close'] < previous_h4_low and next_h4_bar['Close'] < previous_h4_low:
                # body close with bar 2 closing below level
                directional_bias = -1 # set bias as FT to the down side

            else: 
                print('error in setting directional bias down', data.name)
                print(data)
                print('preivous H4 Low', previous_h4_low)
                print('Next Bar', next_h4_bar)
                print('Next Bar2', next_h4_bar2)
                print(h4_data_fractal[data.name-4:data.name+4])
        
        elif data['High'] >= previous_h4_high and H4_high_from_fractal == False: pass 
        elif data['Low'] <= previous_h4_low and H4_low_from_fractal == False: pass

        else: print('Directional bias update error')

def screenshot(current_bar, breached=None, breached2=None):
    global H4_high, H4_low, directional_bias, H4_record, H4_last_fractal_high, H4_last_fractal_low

    # Create new row
    new_data = pd.DataFrame({
        'Datetime': [current_bar.name], 
        'H4_high': [H4_high], 
        'H4_low': [H4_low], 
        'Directional_bias': [directional_bias], 
        'Last_Fractal_High': [H4_last_fractal_high], 
        'Last_Fractal_Low': [H4_last_fractal_low], 
        'result': ['']  # initialize with empty string
    })

    # Check for breached variable and update previous rows if needed
    if breached is not None:
        for index, row in H4_record.iterrows():
            if row['H4_high'] == breached:
                if row['H4_low'] == breached2:
                    H4_record.at[index, 'result'] = 1

            elif row['H4_low'] == breached:
                if row['H4_high'] == breached2:

                    H4_record.at[index, 'result'] = -1

        
    # Append the new data to H4_record
    H4_record = pd.concat([H4_record, new_data], ignore_index=True)

def update_H4_range(current_bar):
    """Updates H4 range to define trading range"""
    global H4_high, H4_low, H4_record, directional_bias, H4_high_from_fractal, H4_low_from_fractal, h4_data  # Declare these variables as global

    if current_bar['High'] > H4_high:
        ### Breach of the 4H range to the up side
        determine_directional_bias(current_bar)
        # Log breach to the upside
        breached = H4_high
        breached2 = H4_low

        # Check if the current bar is a fractal high
        if current_bar['Fractal'] == 'fractal_high' or is_specific_candle_fractal(h4_data, current_bar.name, 1) == 'High':
            H4_high_from_fractal = True
        else: H4_high_from_fractal = False

        H4_high = current_bar['High']

        # Set the low after a breach to the fractal high
        if H4_low == 0: 
            H4_low = current_bar['Low']
            # Check if the current bar is a fractal low
            if current_bar['Fractal'] == 'fractal_low':
                H4_low_from_fractal = True
            else: H4_low_from_fractal = False 

        elif H4_last_fractal_low < current_bar['Low']:
            H4_low = H4_last_fractal_low
            H4_low_from_fractal = True
            if is_specific_candle_fractal(h4_data, current_bar.name, -1) == 'Low':
                H4_low= current_bar['Low']

        elif current_bar['Low'] < H4_last_fractal_low:
            H4_low = current_bar['Low']
            # Check if the current bar is a fractal low
            if current_bar['Fractal'] == 'fractal_low' or is_specific_candle_fractal(h4_data, current_bar.name, -1) == 'Low':
                H4_low_from_fractal = True
            else: H4_low_from_fractal = False 

        else:
            print('Breach to high with no low update')

        screenshot(current_bar, breached, breached2)
        breached = ''
        breached2 = ''

    if current_bar['Low'] < H4_low:
        ### Breach of the H4 range to the down side
        determine_directional_bias(current_bar)

        # Log breach to the down side
        breached = H4_low
        breached2 = H4_high

        # Check if the current bar is a fractal low
        if current_bar['Fractal'] == 'fractal_low' or is_specific_candle_fractal(h4_data, current_bar.name, -1) == 'Low':
            H4_low_from_fractal = True
        else: H4_low_from_fractal = False 

        H4_low = current_bar['Low']

        if H4_high == 0: 
            H4_high = current_bar['High']
            # Check if the current bar is a fractal high
            if current_bar['Fractal'] == 'fractal_high':
                H4_high_from_fractal = True
            else: H4_high_from_fractal = False

        elif H4_last_fractal_high > current_bar['High']:
            H4_high = H4_last_fractal_high
            H4_high_from_fractal = True
            if is_specific_candle_fractal(h4_data, current_bar.name, 1) == 'High' and current_bar['High']:
                H4_high = current_bar['High']
                H4_high_from_fractal = True

        elif current_bar['High'] > H4_last_fractal_high or is_specific_candle_fractal(h4_data, current_bar.name, 1) == 'High' and current_bar['High']:
            H4_high = current_bar['High']
            # Check if the current bar is a fractal high
            if current_bar['Fractal'] == 'fractal_high':
                H4_high_from_fractal = True
            else: H4_high_from_fractal = False

        else:
            print('Breach to low with no high update')

        screenshot(current_bar, breached, breached2)
        breached = ''
        breached2 = ''

def update_h4_fractals(data):
    """ Update the 'last fractals' """
    global H4_last_fractal_high, H4_last_fractal_low, h4_data   # Declare these variables as global
    # Initial update 4H last fractals
    if H4_last_fractal_high == 0 or H4_last_fractal_low == 0:
        H4_last_fractal_high = data['High']
        H4_last_fractal_low = data['Low']

    # Update latest 4H last fractals
    if data['Fractal'] == "fractal_high":
        H4_last_fractal_high = data['High']
        if is_specific_candle_fractal(h4_data, data.name, -1) == 'Low':
            H4_last_fractal_low == data['Low']
        screenshot(data)

    if data['Fractal'] == "fractal_low":
        H4_last_fractal_low = data['Low'] 
        if is_specific_candle_fractal(h4_data, data.name, 1) == 'High':
            H4_last_fractal_high == data['High']
        screenshot(data)
        
def plotH4(data):
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10), sharex=True)
    ax1.plot(data['Datetime'], data['H4_high'], label='H4 High', color='green')
    ax1.plot(data['Datetime'], data['H4_low'], label='H4 Low', color='red')
    ax1.set_ylabel('Price')
    ax1.set_title('H4 High and Low Over Time')
    ax1.legend()
    ax2.plot(data['Datetime'], data['Directional_bias'], label='Directional Bias', color='blue')
    ax2.set_ylabel('Directional Bias')
    ax2.set_title('Directional Bias Over Time')
    ax2.legend()
    ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M:%S'))  # Format dates as you prefer
    ax2.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M:%S'))
    ax1.xaxis.set_major_locator(mdates.HourLocator(interval=4))
    ax2.xaxis.set_major_locator(mdates.HourLocator(interval=4))
    plt.setp(ax1.get_xticklabels(), rotation=45)
    plt.setp(ax2.get_xticklabels(), rotation=45)
    ax1.grid(True)
    ax2.grid(True)
    plt.tight_layout()
    mpf.plot(h4_data, type='candle', style='yahoo', title='Candlestick Chart', ylabel='Price')
    plt.show()

def is_specific_candle_fractal(data, timestamp, HighLow):
    """Checks if the current bar is a fractal high/low.
        Input the price data as a pd dataframe, the timestamp of the bar in question and 1 or -1 to identify if you are looking to check if this is a fractal high or fractal low."""
    index = data.index.get_loc(timestamp)

    fractal_high = data['High'].iloc[index]
    fractal_low = data['Low'].iloc[index]

    start_index = max(0, index - 2)
    end_index = min(len(data) - 1, index + 2)

    is_high = fractal_high >= max(data['High'].iloc[start_index:end_index + 1])
    is_low = fractal_low <= min(data['Low'].iloc[start_index:end_index + 1])

    if HighLow == 1:
        if is_high:
            return 'High'
        else: return False
    
    elif HighLow == -1:
        if is_low:
            return 'Low'
        else: return False
    
    else:
        return False

def update_daily_momentum(daily_data):
    # Initialize momentum and counter for breaches
    daily_momentum = 0  # 0 means no momentum, 1 means bullish, -1 means bearish

    # Create a new column in the dataframe for daily momentum
    daily_data['daily_momentum'] = 0  # Initialize all to 0

    # Keep track of the last breached fractal high and low
    last_fractal_high = None
    last_fractal_low = None
    Unconfirmed_low = None 
    Unconfirmed_high = None
    previous_fractal_high = None
    previous_fractal_low = None

    # Loop through the dataframe
    for i, bar in daily_data.iterrows():

        if last_fractal_high ==  None and bar['Fractal'] == 'fractal_high': 
            last_fractal_high = bar['High']

        if last_fractal_low == None and bar['Fractal'] == 'fractal_low': 
            last_fractal_low = bar['Low']
        
        if last_fractal_low and last_fractal_high is not None:
            
            if Unconfirmed_low is not None:
                # Second Low Breach
                if bar['Low'] < Unconfirmed_low:
                    daily_momentum = -1
                    Unconfirmed_low = None

            if bar['Fractal'] == 'fractal_low':
                if bar['Low'] < last_fractal_low:
                    if daily_momentum == 1 or daily_momentum == 0:
                        if Unconfirmed_low == None:
                            # First Low Breach
                            Unconfirmed_low = bar['Low']
                        
                        if Unconfirmed_high is not None:
                            Unconfirmed_high = None

                previous_fractal_low = bar['Low']


            if bar['Low'] < last_fractal_low:
                if daily_momentum == -1:
                    last_fractal_low = bar['Low']
                    last_fractal_high = previous_fractal_high     

        
            if bar['Fractal'] == 'fractal_high':
                if bar['High'] > last_fractal_high:
                    if daily_momentum == -1 or daily_momentum == 0:
                        if Unconfirmed_high == None:
                            # First Low Breach
                            Unconfirmed_high = bar['High']
                        
                        if Unconfirmed_low is not None:
                            Unconfirmed_low = None

                    if daily_momentum == 1:
                        last_fractal_high = bar['High']
                        last_fractal_low = previous_fractal_low 
                
                previous_fractal_high = bar["High"]

            if bar['High'] > last_fractal_high:
                if Unconfirmed_high is not None:
                    # Second Low Breach
                    if bar['High'] > Unconfirmed_high:
                        daily_momentum = 1


        if daily_momentum != 0:
            daily_data.at[i, 'daily_momentum'] = daily_momentum

    return daily_data[['daily_momentum']]  # Return only 'daily_momentum' column

def set_15min_levels(current_bar):
    """Define critical levels needed for 15min entry."""
    
    global fractal_high, fractal_low, Min15_high, Min15_low, min15_record, fractal_high_validity, fractal_low_validity, recently_updated
    
    # set last 15 min fractal levels
    if current_bar['Fractal'] == "fractal_high":
        fractal_high = current_bar['High']
        fractal_high_validity = 1

        if is_specific_candle_fractal(m15_data_fractal, current_bar.name, -1) == 'Low':
            fractal_low = current_bar['Low'] 
            fractal_low_validity = 1


    if current_bar['Fractal'] == "fractal_low":
        fractal_low = current_bar['Low'] 
        fractal_low_validity = 1

        if is_specific_candle_fractal(m15_data_fractal, current_bar.name, 1) == 'High':
            fractal_low = current_bar['High'] 
            fractal_low_validity = 1

    # set 15 min range
    if current_bar['High'] >= Min15_high:
        Min15_high = current_bar['High']
        Min15_low = fractal_low 
        recently_updated = "up"

    elif current_bar['Low'] <=  Min15_low:
        Min15_low = current_bar['Low']
        Min15_high = fractal_high
        recently_updated = "down"

    else:
        recently_updated = None

    # snap('2023-09-14 11:45:00',current_bar)
    new_data = pd.DataFrame({'Datetime': [current_bar.name], 'M15_high': Min15_high, 'M15_low': Min15_low, 'Last_Fractal_High': fractal_high, 'Last_Fractal_Low': fractal_low})
    min15_record = pd.concat([min15_record, new_data], ignore_index=True) 
    
def check_time_range(current_time):
    """Function to check if the current_time is out of kill zone. Return True if in KZ."""
    # Convert the timestamp to UTC timezone
    # timestamp_utc = timestamp.tz_localize(UTC)

    # # Extract the time from the timestamp
    # current_time = timestamp_utc.time()

    # Define time ranges in UTC
    time_range_1_start = time(8, 0)
    time_range_1_end = time(10, 30)
    time_range_2_start = time(13, 0)
    time_range_2_end = time(15, 30)
    # Check if the time is within either of the defined ranges
    if (time_range_1_start <= current_time < time_range_1_end) or \
        (time_range_2_start <= current_time < time_range_2_end):
        return True
    else:
        return False

def check_sweep_origin(min15_data_fractal, current_index, search_color):
    """Checks where the liquidity sweep originates.
    Return True when the sweep origin is within the KZ."""
    last_opposite_color_index = None
    current_index_int = min15_data_fractal.index.get_loc(current_index)

    for index, row in min15_data_fractal.iloc[current_index_int-1::-1].iterrows():
        if row['Bar'] == search_color:
            last_opposite_color_index = min15_data_fractal.index[min15_data_fractal.index.get_loc(index)+1]
            break  # Exit the loop as soon as an opposite color is found

    # If no opposite color candle was found, return False
    if not last_opposite_color_index:
        return False

    # Convert the last opposite color change timestamp to UTC and extract its time
    last_opposite_color_time = last_opposite_color_index.tz_localize(UTC).time()
    
    # print('sweep check time:', last_opposite_color_time)

    return check_time_range(last_opposite_color_time)  # Returns true when in KZ

def get_last_daily_momentum(before_datetime):
    # Filter out rows after the current 15-min datetime
    filtered_df = d1_data_momentum[d1_data_momentum.index < before_datetime]

    # Return the daily_momentum of the last row, if the filtered_df is not empty
    if not filtered_df.empty:
        return filtered_df.iloc[-1]['daily_momentum']
    return None

def check_15min_entry(data, Stop_Pips):
    """Check for an entry. Place Limit order if entry is found."""
    global m15_data_fractal, fractal_high, fractal_low, Min15_high, Min15_low, min15_record, fractal_high_validity, fractal_low_validity, recently_updated, Pending_orders, H4_high, H4_low, directional_bias, H4_high_from_fractal, H4_low_from_fractal, h4_data_fractal, d1_data_momentum  # Declare these variables as global

    if data['High'] > 0 and data['Low'] > 0 and \
        data['High'] < H4_high and data['Low'] > H4_low and \
        Min15_high > 0 and Min15_low > 0 and \
        fractal_high > 0 and fractal_low > 0:
        # Not sure if needed, but I guess this stops entries if the current bar is out of H4 range. Could need a way to stop all entries until H4 is updated?
       
        if data['High'] > Min15_high or (data['High'] > fractal_high and fractal_high_validity ==1):
            Momentum = get_last_daily_momentum(data.name)
            dead_high = H4_low + ((H4_high - H4_low) * 0.55)
            if ((directional_bias == 1 or Momentum == 1) and (data['Low'] > dead_high)) or (directional_bias == 2):
                if check_time_range(data.name.time()) and check_sweep_origin(m15_data_fractal, data.name, "Red"):
                
                    if recently_updated == "up":
                        recently_updated = False
                        set_15min_levels(data)
                        return
                
                    SELL(data, Stop_Pips)

            fractal_high_validity = 0

        if data['Low'] < Min15_low or (data['Low'] < fractal_low and fractal_low_validity ==1):
            Momentum = get_last_daily_momentum(data.name)
            dead_low = H4_low + ((H4_high - H4_low) * 0.45)
            if ((directional_bias == -1 or Momentum == -1) and (data['High'] < dead_low)) or (directional_bias == -2):
                if check_time_range(data.name.time()) and check_sweep_origin(m15_data_fractal, data.name, "Green"):

                    if recently_updated == "down":
                        recently_updated = False
                        set_15min_levels(data)
                        return

                    BUY(data, Stop_Pips)
            
            fractal_low_validity = 0

    set_15min_levels(data)

def check_limit(data):
    global Pending_orders, Active_orders

    if not Pending_orders.empty:
        # Close Pending Orders
        if data.name.time() == time(10,30) or data.name.time() == time(15, 30):
            for index, order in Pending_orders.iterrows():
                Pending_orders.drop(index, inplace=True)

        # Fill Stop Order if tagged in
        for index, order in Pending_orders.iterrows():
            if order['Type'] == 'BUY' and data['High'] > order['Limit']:

                new_order = pd.DataFrame({
                'Datetime': [order['Datetime']],
                'Type': [order['Type']], 
                'Limit': [order['Limit']], 
                'SL': [order['SL']],
                'TP': [order['TP']]})

                Active_orders = pd.concat([Active_orders, new_order], ignore_index=True)
                if index in Pending_orders.index:
                    Pending_orders.drop(index, inplace=True)
 
            elif order['Type'] == 'SELL' and data['Low'] < order['Limit']:
            
                new_order = pd.DataFrame({
                'Datetime': [order['Datetime']],
                'Type': [order['Type']], 
                'Limit': [order['Limit']], 
                'SL': [order['SL']],
                'TP': [order['TP']]})

                Active_orders = pd.concat([Active_orders, new_order], ignore_index=True)
                Pending_orders.drop(index, inplace=True)  
        
        # or close if SL is breached before it is tagged in
            elif order['Type'] == 'BUY' and data['Low'] < order['SL']:
                if index in Pending_orders.index:
                    Pending_orders.drop(index, inplace=True)

            elif order['Type'] == 'SELL' and data['High'] > order['SL']:
                if index in Pending_orders.index:
                    Pending_orders.drop(index, inplace=True)

        # print('Active Orders from check_limit_close', Active_orders)

def check_close(data):
    global Active_orders, Closed_orders
    if not Active_orders.empty:

        for index, order in Active_orders.iterrows():
            if (order['Type'] == 'BUY' and data['High'] > order['TP']) or \
            (order['Type'] == 'SELL' and data['Low'] < order['TP']):
                
                new_order = pd.DataFrame({
                'Datetime': [order['Datetime']],
                'Type': [order['Type']], 
                'Limit': [order['Limit']], 
                'SL': [order['SL']],
                'TP': [order['TP']],
                'Close Datetime': [data.name],
                'Return': 3})

                Closed_orders = pd.concat([Closed_orders, new_order], ignore_index=True)
                Active_orders.drop(index, inplace=True)

            if (order['Type'] == 'BUY' and data['Low'] <= order['SL']) or \
            (order['Type'] == 'SELL' and data['High'] >= order['SL']):
                
                new_order = pd.DataFrame({
                'Datetime': [order['Datetime']],
                'Type': [order['Type']], 
                'Limit': [order['Limit']], 
                'SL': [order['SL']],
                'TP': [order['TP']],
                'Close Datetime': [data.name],
                'Return': -1})

                Closed_orders = pd.concat([Closed_orders, new_order], ignore_index=True)
                if index in Active_orders.index:
                    Active_orders.drop(index, inplace=True)
        # print('Closed Orders from check_close', Closed_orders)

def BUY(data, Stop_Pips):
    global Pending_orders

    Long_StopLoss = round(data['Low'], 4) - Stop_Pips
    Long_TakeProfit = round((data['High'] + (3*(data['High']-Long_StopLoss))),4)

    # if Long_TakeProfit >= H4_high:
        # return

    # Add Limit Order to open_orders to track pending orders
    new_order = pd.DataFrame({
        'Datetime': [data.name],
        'Type': ['BUY'], 
        'Limit': [round(data['High'], 4)], 
        'SL': [Long_StopLoss],
        'TP': [Long_TakeProfit]})
    
    # print("new order", new_order)
    Pending_orders = pd.concat([Pending_orders, new_order], ignore_index=True)

def SELL(data, Stop_Pips):
    global Pending_orders

    Short_StopLoss = round(data['High'], 4) + Stop_Pips
    Short_TakeProfit = round((data['Low'] - (3*(Short_StopLoss-data['Low']))),4)

    # if Short_TakeProfit <= H4_low:
    #     return  

    # Add Limit Order to open_orders to track pending orders
    new_order = pd.DataFrame({
        'Datetime': [data.name],
        'Type': ['SELL'], 
        'Limit': [round(data['Low'], 4)], 
        'SL': [Short_StopLoss],
        'TP': [Short_TakeProfit]})
    
    # print("new order", new_order)
    Pending_orders = pd.concat([Pending_orders, new_order], ignore_index=True)
 
def process_results(Closed_orders, H4_record, daily_momentum_data):
    # Set 'Close Datetime' as the index
    Closed_orders.set_index('Close Datetime', inplace=True)
    Closed_orders.index = pd.to_datetime(Closed_orders.index)

    # Group by month and sum the 'Return' column
    monthly_returns = Closed_orders['Return'].resample('M').sum().reset_index()
    Pos_Month_rate = (len(Closed_orders[Closed_orders['Return'] > 0]) / len(Closed_orders)) * 100

    print("Total Return:", Closed_orders['Return'].sum())
    print('Percentage positive months:', Pos_Month_rate)
    print("Monthly Return Breakdown:\n", monthly_returns)

    s = (Closed_orders['Return'] == -1)
    groups = s.ne(s.shift()).cumsum()
    consecutive_negatives = s.groupby(groups).cumsum()
    max_drawdown = consecutive_negatives.max()

    print("Max Drawdown:", max_drawdown)

    # # Plotting
    # fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(10, 10))

    # # 1. Line graph for cumulative sum of 'Return'
    # Closed_orders['Return'].cumsum().plot(ax=ax[0])
    # ax[0].set_title("Cumulative Sum of Returns")
    # ax[0].set_xlabel("Date")
    # ax[0].set_ylabel("Cumulative Return")

    # # 2. Bar chart for monthly sum of 'Return'
    # monthly_returns = Closed_orders['Return'].resample('M').sum()
    # monthly_returns.plot(kind='bar', ax=ax[1])
    # ax[1].set_title("Monthly Sum of Returns")
    # ax[1].set_xlabel("Month")
    # ax[1].set_ylabel("Return")
    # plt.tight_layout()

    # plt.show()

    # H4 Levels Analysis
    # Merge daily momentum data into df based on the index
    df = H4_record
    if isinstance(H4_record.index, pd.DatetimeIndex):
        df['date'] = df.index.date
    else:
        df['date'] = pd.to_datetime(df['Datetime']).dt.date

    daily_momentum_data = daily_momentum_data.copy()
    daily_momentum_data.loc[:, 'date'] = daily_momentum_data.index.date

    # Merge daily momentum data into df based on the 'date'
    df = df.merge(daily_momentum_data, on='date', how='left')
    df.drop('date', axis=1, inplace=True)

    # Remove rows where Directional_bias is 0
    df = df[(df['Directional_bias'] != 0)]

    # Drop consecutive duplicates based on H4_high and H4_low
    df = df[df[['H4_high', 'H4_low']].ne(df[['H4_high', 'H4_low']].shift()).any(axis=1)]
    
    # H4_record.to_csv('H4_levels_directional_bias_check.csv')
    # df.to_csv('H4_Ranges_w_Results.csv')

    # Filter rows where Directional_bias and daily_momentum are both positive or both negative
    aligned_df = df[((df['Directional_bias'] > 0) & (df['daily_momentum'] > 0)) |
                    ((df['Directional_bias'] < 0) & (df['daily_momentum'] < 0))]
    
    # Count number of successes in the aligned_df
    positive_aligned_success = aligned_df[(aligned_df['Directional_bias'] > 0) & (aligned_df['result'] == 1)].shape[0]
    negative_aligned_success = aligned_df[(aligned_df['Directional_bias'] < 0) & (aligned_df['result'] == -1)].shape[0]
    high_prob_success = positive_aligned_success + negative_aligned_success
    
    # Calculate high probability success rate
    high_prob_rate = (high_prob_success / len(aligned_df)) * 100 if len(aligned_df) != 0 else 0

    # Exclude rows where Directional_bias and daily_momentum are aligned
    non_aligned_df = df[~((df['Directional_bias'] > 0) & (df['daily_momentum'] > 0)) &
                        ~((df['Directional_bias'] < 0) & (df['daily_momentum'] < 0))]

    # Calculate successful counts for Directional_bias from non_aligned_df
    positive_bias_success = non_aligned_df[(non_aligned_df['Directional_bias'] > 0) & (non_aligned_df['result'] == 1)].shape[0]
    negative_bias_success = non_aligned_df[(non_aligned_df['Directional_bias'] < 0) & (non_aligned_df['result'] == -1)].shape[0]
    total_bias_success = positive_bias_success + negative_bias_success
    Directional_bias_success_rate = (total_bias_success / len(non_aligned_df)) * 100 if len(non_aligned_df) != 0 else 0  # Handle potential division by zero
    
    # Calculate successful counts for daily_momentum from non_aligned_df
    positive_momentum_success = non_aligned_df[(non_aligned_df['daily_momentum'] > 0) & (non_aligned_df['result'] == 1)].shape[0]
    negative_momentum_success = non_aligned_df[(non_aligned_df['daily_momentum'] < 0) & (non_aligned_df['result'] == -1)].shape[0]
    total_momentum_success = positive_momentum_success + negative_momentum_success
    daily_momentum_success_rate = (total_momentum_success / len(non_aligned_df)) * 100 if len(non_aligned_df) != 0 else 0  # Handle potential division by zero
    
    return high_prob_rate, Directional_bias_success_rate

def run(df, Stop_Pips):
    """Run the analysis. \n
    df = the 15 min price data including High, Open, Close, Low \n
    Stop_pips to indicate how many pips are added to SL """
    
    global h4_data, h4_data_fractal, H4_record, H4_last_fractal_high, H4_last_fractal_low, H4_high, H4_low, H4_high_from_fractal, H4_low_from_fractal, H4_equ,directional_bias,fractal_high, fractal_low, Min15_high, Min15_low, fractal_high_validity, fractal_low_validity,min15_record, recently_updated,Pending_orders,Active_orders,Closed_orders, m15_data_fractal,d1_data_momentum

    df['timestamp'] = pd.to_datetime(df["timestamp"], unit = "ms")
    df.set_index('timestamp', inplace=True)
    column_mapping = {
        'open': 'Open',
        'high': 'High',
        'low': 'Low',
        'close': 'Close',
        'volume': 'Volume'
    }
    df = df.rename(columns=column_mapping)
    # Remove rows where 'Volume' is equal to 0
    df = df[df['Volume'] != 0]

    # Resample to 4-hour data with custom time offset 
    h4_data = df.resample('4H', offset='2H').agg({
        'Open': 'first',
        'High': 'max',
        'Low': 'min',
        'Close': 'last',
        'Volume': 'sum'
    })

    # Resample to daily data 3.11 CHANGE to weekly data
    d1_data = df.resample('1D').agg({
        'Open': 'first',
        'High': 'max',
        'Low': 'min',
        'Close': 'last',
        'Volume': 'sum'
    })

    # Identify fractal H/L for all data (A bit of look ahead bias here?)
    m15_data_fractal_1 = identify_fractals(df)
    m15_data_fractal = identify_bar(m15_data_fractal_1)
    h4_data_fractal_1 = identify_fractals(h4_data)
    h4_data_fractal = identify_bar(h4_data_fractal_1)
    d1_data_fractal_1 = identify_fractals(d1_data)
    d1_data_fractal = identify_bar(d1_data_fractal_1)

    # Identify daily momentum
    d1_data_momentum = update_daily_momentum(d1_data_fractal)

    # Create the H4 record 
    H4_record = pd.DataFrame(columns=['Datetime','H4_high', 'H4_low','Last_Fractal_High','Last_Fractal_Low', 'Directional_bias'])

    # H4 Variables
    H4_last_fractal_high = 0
    H4_last_fractal_low = 0
    H4_high = 0
    H4_low = 0
    H4_high_from_fractal = False
    H4_low_from_fractal = False
    H4_equ = 0
    directional_bias = 0

    # m15 Variables
    fractal_high, fractal_low, Min15_high, Min15_low, fractal_high_validity, fractal_low_validity = 0,0,0,0,0,0
    min15_record = pd.DataFrame(columns=['Datetime','M15_high', 'M15_low'])
    recently_updated = False
    Pending_orders = pd.DataFrame(columns = ['Datetime', 'Type', 'Limit', 'SL', 'TP'])
    Active_orders = pd.DataFrame(columns = ['Datetime', 'Type', 'Limit', 'SL', 'TP'])
    Closed_orders = pd.DataFrame(columns = ['Datetime', 'Type', 'Limit', 'SL', 'TP', 'Close Datetime','Return'])


    #### Main Loop ###
    for  index, bar in tqdm(m15_data_fractal.iterrows()):
        check_close(bar)
        check_limit(bar)
        check_15min_entry(bar, Stop_Pips)
        if index in h4_data_fractal.index:
            update_H4_range(bar)
            update_h4_fractals(bar)

    high_prob_rate, directional_bias_success_rate = process_results(Closed_orders, H4_record, d1_data_momentum)
    print(f"High Probability Success Rate: {high_prob_rate:.2f}%")
    print(f"4H Directional Bias Success Rate: {directional_bias_success_rate:.2f}%")

#####################################################################################################################
# Import 15 min data

# print('GBPUSD Test Analysis')
# df = pd.read_csv("/Users/hugowatkinson/Documents/Trading/Historical Data/gbpusd-m15-bid-2022-09-16-2023-09-16.csv")
# df = df.iloc[(-40*100):]
# run(df)

print('EURUSD analysis')
df = pd.read_csv("/Users/hugowatkinson/Documents/Trading/Historical Data/eurusd-m15-bid-2020-09-16-2023-09-16.csv")
run(df, 0.0003)

print('GBPUSD analysis')
df = pd.read_csv("/Users/hugowatkinson/Documents/Trading/Historical Data/gbpusd-m15-bid-2020-09-16-2023-09-16.csv")
run(df, 0.0003)

print('USDCHF analysis')
df = pd.read_csv("/Users/hugowatkinson/Documents/Trading/Historical Data/usdchf-m15-bid-2020-09-16-2023-09-16.csv")
run(df, 0.0003)
